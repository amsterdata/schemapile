{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and file details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geacu\\AppData\\Local\\Temp\\ipykernel_7320\\2489133733.py:27: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.dataframe.utils import make_meta\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "from src_new.utils import SQLParserSchema, PGLastSchema, get_file_encodings, SQLGlotSchema, SimpleDDLParserSchema\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_partial(parser, schema_type, cols):\n",
    "    _outdir = '../out_new/'\n",
    "\n",
    "    if parser == 'sqlparser':\n",
    "        p = SQLParserSchema()\n",
    "        _outdir += 'sqlparser'\n",
    "    elif parser == 'pglast':\n",
    "        p = PGLastSchema()\n",
    "        _outdir += 'pglast'\n",
    "    elif parser == 'sqlglot':\n",
    "        p = SQLGlotSchema()\n",
    "        _outdir += 'sqlglot'\n",
    "    elif parser == 'simple':\n",
    "        p = SimpleDDLParserSchema()\n",
    "        _outdir += 'simpleddlparser'\n",
    "    \n",
    "    if schema_type == 'file':\n",
    "        _schema = p.file_level_schema\n",
    "        _outdir += '/'\n",
    "    elif schema_type == 'stmt':\n",
    "        _schema = p.statement_list_sch\n",
    "        _outdir += '_details/'\n",
    "    \n",
    "    ddf = dd.read_parquet(_outdir,columns=cols, schema=_schema, split_row_groups=True, calculate_divisions=True,engine='pyarrow')\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file details\n",
    "fd = []\n",
    "for file in os.listdir('../out_new/filedetails/'):\n",
    "        full_filename = \"%s/%s\" % ('../out_new/filedetails/', file)\n",
    "        with open(full_filename,'r') as fi:\n",
    "            dict = json.load(fi)\n",
    "            for item in dict:\n",
    "                  fd.append(item)\n",
    "\n",
    "filedetails_df = pd.DataFrame.from_dict(fd)\n",
    "del fd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_ddf = read_partial('simple','file',SimpleDDLParserSchema().file_level_schema.names)\n",
    "sdp_details_ddf = read_partial('simple','stmt',SimpleDDLParserSchema().statement_list_sch.names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Level SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 809.55 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>308265</td>\n",
       "      <td>0.826102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64891</td>\n",
       "      <td>0.173898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   success   count  percentage\n",
       "0  0        308265  0.826102  \n",
       "1  1        64891   0.173898  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdp_sr = sdp_ddf.groupby('parsed_file')['parsed_file'].count().compute()\n",
    "sdp_sr = pd.DataFrame({'success':[0,1], 'count':[sdp_sr[sdp_sr.index != 1].sum(),sdp_sr[sdp_sr.index == 1].sum()]})\n",
    "sdp_sr['percentage'] = sdp_sr['count']/filedetails_df['file_id'].count()\n",
    "display(sdp_sr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including exceptions but results given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 1.29 sms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37783</td>\n",
       "      <td>0.101253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>223337</td>\n",
       "      <td>0.598508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   success   count  percentage\n",
       "0  0        37783   0.101253  \n",
       "1  1        223337  0.598508  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdp_exc_ddf = sdp_ddf[(sdp_ddf.parsed_file == 0) | \n",
    "                      (sdp_ddf.parsed_file == 1) | \n",
    "                      ((sdp_ddf.parsed_file == 2) & \n",
    "                        ((sdp_ddf.num_distinct_tables > 0) |\n",
    "                         (sdp_ddf.num_distinct_columns > 0) |\n",
    "                         (sdp_ddf.num_constraints > 0)\n",
    "                        )\n",
    "                      )\n",
    "            ]\n",
    "sdp_exc_sr = sdp_exc_ddf.groupby('parsed_file')['parsed_file'].count().compute()\n",
    "sdp_exc_sr = pd.DataFrame({'success':[0,1], 'count':[sdp_exc_sr[sdp_exc_sr.index == 0].sum(),sdp_exc_sr[sdp_exc_sr.index != 0].sum()]})\n",
    "sdp_exc_sr['percentage'] = sdp_exc_sr['count']/filedetails_df['file_id'].count()\n",
    "display(sdp_exc_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 655.76 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>parsed_file</th>\n",
       "      <th>value_error_present</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parsed_file</th>\n",
       "      <th>value_error_present</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>37714</td>\n",
       "      <td>37714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>62894</td>\n",
       "      <td>62894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>270482</td>\n",
       "      <td>270482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 parsed_file  value_error_present\n",
       "parsed_file value_error_present                                  \n",
       "0           0                    37714        37714              \n",
       "1           0                    62894        62894              \n",
       "            1                    1997         1997               \n",
       "2           0                    270482       270482             \n",
       "0           1                    69           69                 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp_ddf.groupby(['parsed_file','value_error_present'])['parsed_file','value_error_present'].count().compute()\n",
    "# 1 4.5k\n",
    "# 0 19.4k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching with pglast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pglast_ddf = read_partial('pglast','file',PGLastSchema().file_level_schema.names)\n",
    "sdp_ddf = read_partial('simple','file',SimpleDDLParserSchema().file_level_schema.names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining and writing down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 64.63 s\n"
     ]
    }
   ],
   "source": [
    "pglast_ddf = read_partial('pglast','file',PGLastSchema().file_level_schema.names)\n",
    "sdp_ddf = read_partial('simple','file',SimpleDDLParserSchema().file_level_schema.names)\n",
    "# filtering\n",
    "#pglast_ddf['p'] = pglast_ddf['parsed_file']\n",
    "#sqlglot_ddf['p'] = sqlglot_ddf['parsed_postgres']\n",
    "sdp_ddf = sdp_ddf[(sdp_ddf.parsed_file == 1) | \n",
    "                    ((sdp_ddf.parsed_file == 2) & \n",
    "                    ((sdp_ddf.num_distinct_tables > 0) |\n",
    "                     (sdp_ddf.num_distinct_columns > 0) |\n",
    "                     (sdp_ddf.num_constraints > 0)\n",
    "                    )\n",
    "                  )]\n",
    "pglast_ddf = pglast_ddf[pglast_ddf.parsed_file == 1]\n",
    "\n",
    "try:\n",
    "    del dict\n",
    "except:\n",
    "    pass\n",
    "# renaming cols\n",
    "sdp_ddf = sdp_ddf.rename(columns=dict(zip(sdp_ddf.columns, [item.replace(\"sdp_file_id\",\"file_id\") for item in [\"sdp_\" + item for item in sdp_ddf.columns]])))\n",
    "pglast_ddf = pglast_ddf.rename(columns=dict(zip(pglast_ddf.columns, [item.replace(\"pglast_file_id\",\"file_id\") for item in [\"pglast_\" + item for item in pglast_ddf.columns]])))\n",
    "\n",
    "pglast_joined_sdp= dd.merge(\n",
    "    sdp_ddf,\n",
    "    pglast_ddf,\n",
    "    on=['file_id'],\n",
    "    how='outer',indicator=True,suffixes=['_sdp','_pglast'])\n",
    "\n",
    "join_schema = pa.schema([])\n",
    "join_schema = join_schema.append(pa.field(\"file_id\",pa.string()))\n",
    "\n",
    "for item in SimpleDDLParserSchema().file_level_schema:\n",
    "    if item.name != 'file_id':\n",
    "        join_schema = join_schema.append(pa.field(\"sdp_\" + item.name,item.type))\n",
    "for item in PGLastSchema().file_level_schema:\n",
    "    if item.name != 'file_id':\n",
    "        join_schema = join_schema.append(pa.field(\"pglast_\" + item.name,item.type))\n",
    "\n",
    "join_schema = join_schema.append(pa.field(\"_merge\",pa.string()))\n",
    "#pglast_joined_sdp.to_parquet('../out_new/join__parsed__pglast_sdp/',schema=join_schema,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_ddf = dd.read_parquet('../out_new/join__parsed__pglast_sdp/', schema=join_schema, split_row_groups=True, calculate_divisions=True,engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 702.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          54573 \n",
       "left_only     168764\n",
       "right_only    9364  \n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_ddf.groupby('_merge')['_merge'].count().compute()\n",
    "\n",
    "# better than sqlglot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parsed files match on: parsed + number of extracted tables?\n",
    "worse than sqlglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 8.91 ss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30746"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_both_ddf = joined_ddf[joined_ddf['_merge'] == 'both']\n",
    "\n",
    "# removing create seq stmt cause apparently it affects num tables\n",
    "import ast\n",
    "parsed_both_ddf['x'] = parsed_both_ddf.apply(\n",
    "    lambda row:\n",
    "    [item for item in ast.literal_eval(row['pglast_counter_str']) if 'CreateSeqStmt' in item],\n",
    "    axis=1,\n",
    "    meta=('x', 'string'))\n",
    "parsed_both_ddf['pglast_num_create_seq'] = parsed_both_ddf.apply(\n",
    "    lambda row:\n",
    "    row['x'][0]['CreateSeqStmt'] if len(row['x']) > 0 else 0,\n",
    "    axis=1,\n",
    "    meta=('pglast_num_create_seq', 'float'))\n",
    "\n",
    "parsed_both_ddf['sdp_nt'] = parsed_both_ddf['sdp_num_distinct_tables']\n",
    "parsed_both_ddf['pglast_nt'] = parsed_both_ddf['pglast_num_distinct_tables'] - parsed_both_ddf['pglast_num_create_seq']\n",
    "\n",
    "parsed_both_ddf[parsed_both_ddf.sdp_nt == parsed_both_ddf.pglast_nt]['file_id'].count().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 9.06 ss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45879"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_both_ddf[parsed_both_ddf.pglast_num_distinct_columns == parsed_both_ddf.sdp_num_distinct_columns]['file_id'].count().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match on constraints\n",
    "\n",
    "notnull: 31360\n",
    "unique: 47930\n",
    "primary: 30069\n",
    "foreign: 16188\n",
    "all: 4541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 9.97 ss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4541"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_both_ddf[(parsed_both_ddf.sdp_num_ctr_notnull == parsed_both_ddf.pglast_num_ctr_notnull) &\n",
    "                (parsed_both_ddf.sdp_num_ctr_unique == parsed_both_ddf.pglast_num_ctr_unique) &\n",
    "                (parsed_both_ddf.sdp_num_ctr_primary == parsed_both_ddf.pglast_num_ctr_primary) &\n",
    "                (parsed_both_ddf.sdp_num_ctr_foreign == parsed_both_ddf.pglast_num_ctr_foreign)\n",
    "                ]['file_id'].count().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match on table list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26105"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_both_ddf_tl = parsed_both_ddf.dropna(subset=['sdp_table_list','pglast_table_list'])\n",
    "parsed_both_ddf_tl['sdp_tl'] = parsed_both_ddf_tl.apply(\n",
    "    lambda row:\n",
    "    \"|\".join(str(x) for x in sorted(row['sdp_table_list'])),\n",
    "    axis=1,\n",
    "    meta=('sdp_tl', 'string'))\n",
    "parsed_both_ddf_tl['pglast_tl'] = parsed_both_ddf_tl.apply(\n",
    "    lambda row:\n",
    "    \"|\".join(str(x) for x in sorted(row['pglast_table_list'])),\n",
    "    axis=1,\n",
    "    meta=('pglast_tl', 'string'))\n",
    "\n",
    "parsed_both_ddf_tl[parsed_both_ddf_tl.pglast_tl == parsed_both_ddf_tl.sdp_tl]['file_id'].count().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match on col list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 11.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_both_ddf_cl = parsed_both_ddf.dropna(subset=['sdp_column_list','pglast_columns_list'])\n",
    "parsed_both_ddf_cl['sdp_cl'] = parsed_both_ddf_cl.apply(\n",
    "    lambda row:\n",
    "    \"|\".join(str(x) for x in sorted(row['sdp_column_list'])),\n",
    "    axis=1,\n",
    "    meta=('sdp_cl', 'string'))\n",
    "parsed_both_ddf_cl['pglast_cl'] = parsed_both_ddf_cl.apply(\n",
    "    lambda row:\n",
    "    \"|\".join(str(x) for x in sorted(row['pglast_columns_list'])),\n",
    "    axis=1,\n",
    "    meta=('pglast_cl', 'string'))\n",
    "\n",
    "parsed_both_ddf_cl[parsed_both_ddf_cl.pglast_cl == parsed_both_ddf_cl.sdp_cl]['file_id'].count().compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
