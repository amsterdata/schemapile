{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907ac749",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# prepare starcoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4a844",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install jsonformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbaf8af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fix jsonformer\n",
    "def apply_generate_array_fix(jsonformer):\n",
    "    def generate_array(item_schema, obj) -> list:\n",
    "        for _ in range(jsonformer.max_array_length):\n",
    "            # forces array to have at least one element\n",
    "            element = jsonformer.generate_value(item_schema, obj)\n",
    "            obj[-1] = element\n",
    "\n",
    "            obj.append(jsonformer.generation_marker)\n",
    "            input_prompt = jsonformer.get_prompt()\n",
    "            obj.pop()\n",
    "            input_tensor = jsonformer.tokenizer.encode(input_prompt, return_tensors=\"pt\")\n",
    "            output = jsonformer.model.forward(input_tensor.to(jsonformer.model.device))\n",
    "            logits = output.logits[0, -1]\n",
    "\n",
    "\n",
    "            top_indices = logits.topk(30).indices\n",
    "            sorted_token_ids = top_indices[logits[top_indices].argsort(descending=True)]\n",
    "\n",
    "            found_comma = False\n",
    "            found_close_bracket = False\n",
    "            for token_id in sorted_token_ids:\n",
    "                decoded_token = jsonformer.tokenizer.decode(token_id)\n",
    "                if '{' in decoded_token:\n",
    "                    found_comma = True\n",
    "                    break\n",
    "                if ']' in decoded_token:\n",
    "                    found_close_bracket = True\n",
    "                    break\n",
    "\n",
    "            if found_close_bracket or not found_comma:\n",
    "                break\n",
    "\n",
    "        return obj\n",
    "    \n",
    "    def get_prompt():\n",
    "        template = \"\"\"{prompt}{progress}\"\"\"\n",
    "        progress = json.dumps(jsonformer.value)\n",
    "        gen_marker_index = progress.find(f'\"{jsonformer.generation_marker}\"')\n",
    "        if gen_marker_index != -1:\n",
    "            progress = progress[:gen_marker_index]\n",
    "        else:\n",
    "            raise ValueError(\"Failed to find generation marker\")\n",
    "\n",
    "        prompt = template.format(\n",
    "            prompt=jsonformer.prompt,\n",
    "            #schema=json.dumps(jsonformer.json_schema),\n",
    "            progress=progress,\n",
    "        )\n",
    "\n",
    "        return prompt\n",
    "    jsonformer.get_prompt = get_prompt \n",
    "    jsonformer.generate_array = generate_array\n",
    "    return jsonformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682debb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from dialogues import DialogueTemplate, get_dialogue_template\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer,\n",
    "                          GenerationConfig, set_seed)\n",
    "from jsonformer import Jsonformer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "\n",
    "def initialize_model(model_id, tokenizer_model_id=None):\n",
    "    if not tokenizer_model_id:\n",
    "        tokenizer_model_id = model_id\n",
    "    revision = None\n",
    "    system_prompt = None\n",
    "    set_seed(42)\n",
    "\n",
    "    try:\n",
    "        dialogue_template = DialogueTemplate.from_pretrained(model_id, revision=revision)\n",
    "    except Exception:\n",
    "        print(\"No dialogue template found in model repo. Defaulting to the `no_system` template.\")\n",
    "        dialogue_template = get_dialogue_template(\"no_system\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_model_id, revision=revision)\n",
    "    tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(dialogue_template.end_token)\n",
    "    tokenizer.eos_token_id = tokenizer.eos_token_id\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=float(0.01),\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.convert_tokens_to_ids(dialogue_template.end_token),\n",
    "        min_new_tokens=32,\n",
    "        max_new_tokens=512,\n",
    "    )\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, revision=revision, load_in_8bit=True, device_map=\"auto\", torch_dtype=torch.float16\n",
    "    )\n",
    "    #config = PeftConfig.from_pretrained(model_id)\n",
    "    #model = PeftModel.from_pretrained(model, config)\n",
    "\n",
    "    \n",
    "    return model, tokenizer, dialogue_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713548a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def generate_response_as_json_starcoder(prompt_text):\n",
    "    prompt =[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_text,\n",
    "        }\n",
    "    ]\n",
    "    dialogue_template.messages = [prompt] if isinstance(prompt, dict) else prompt\n",
    "    formatted_prompt = dialogue_template.get_inference_prompt()\n",
    "\n",
    "    src_table, src_cols, trg_table, trg_cols = get_enums_from_prompt_text(prompt_text)\n",
    "    \n",
    "    json_schema_fk = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                      \"table\": { \n",
    "                          \"type\": \"enum\",\n",
    "                          \"values\": [src_table]\n",
    "                      },\n",
    "                      \"column\": { \n",
    "                        \"type\": \"enum\",\n",
    "                        \"values\": src_cols\n",
    "                      },\n",
    "                      \"referencedTable\": { \n",
    "                          \"type\": \"enum\",\n",
    "                          \"values\": [trg_table]\n",
    "                      },\n",
    "                      \"referencedColumn\": { \n",
    "                        \"type\": \"enum\",\n",
    "                        \"values\": trg_cols\n",
    "                      },\n",
    "                    },\n",
    "            \"required\": [\"table\", \"column\", \"referencedTable\", \"referencedColumn\"],\n",
    "    }\n",
    "    \n",
    "\n",
    "    jsonformer = Jsonformer(model, tokenizer, json_schema_fk, formatted_prompt, debug = False)\n",
    "    apply_generate_array_fix(jsonformer)\n",
    "    result_json = jsonformer()\n",
    "    \n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0298027",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# prepare openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a3f488",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def generate_response_as_json_gpt35(prompt_text):\n",
    "        src_table, src_cols, trg_table, trg_cols = get_enums_from_prompt_text(prompt_text)\n",
    "\n",
    "        functions = [\n",
    "        {\n",
    "            \"name\": \"get_foreign_key\",\n",
    "            \"description\": \"Get foreign keys\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"table\": { \n",
    "                        \"type\": \"string\" ,\n",
    "                        \"values\": [src_table]\n",
    "                      },\n",
    "                      \"column\": { \n",
    "                        \"type\": \"string\",\n",
    "                        \"values\": src_cols\n",
    "                      },\n",
    "                      \"referencedTable\": { \n",
    "                        \"type\": \"string\", \n",
    "                        \"values\": [trg_table]\n",
    "                      },\n",
    "                      \"referencedColumn\": { \n",
    "                        \"type\": \"string\",\n",
    "                        \"values\": trg_cols\n",
    "                      },\n",
    "                },\n",
    "                \"required\": [\"table\", \"column\", \"referencedTable\", \"referencedColumn\"],\n",
    "            },\n",
    "        }]\n",
    "        foreign_keys_llm = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that always returns responses in JSON without any additional explanations. Only Respond with the desired JSON, NOTHING else, no explanations.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_text},\n",
    "            ],\n",
    "            functions = functions,\n",
    "            temperature=0,\n",
    "        )[\"choices\"][0][\"message\"]\n",
    "        \n",
    "        return json.loads(foreign_keys_llm[\"function_call\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4808e842",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# prepare t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f62ba1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq,  Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model_name = \"t5-base-schemapile\"\n",
    "model_dir = f\"../../data/{model_name}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "max_input_length = 1024\n",
    "\n",
    "def generate_responses_as_json_t5(prompt):\n",
    "    inputs = [prompt]\n",
    "    inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, num_beams=8, do_sample=False, min_length=10, max_length=512)\n",
    "    decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    try:\n",
    "        output_json = json.loads('{'+decoded_output+\"}\")\n",
    "    except Exception as e:\n",
    "        print('{'+decoded_output+\"}\")\n",
    "        raise e\n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c110f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# load ground truth with additioal fk-filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ae532",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('../../data/data/foreign_keys_instruction_data_schemapile')\n",
    "ds = dataset['train']['messages']\n",
    "fks_schemapile = set([d[1]['content'].lower() for d in ds])\n",
    "json.dump(list(fks_schemapile), open('fks_schemapile.json','w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cc15ed3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fks_schemapile = set(json.load(open('fks_schemapile.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4474c554",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset_from_fk_pairs(prompts_ground_truth):\n",
    "    prompts_ground_truth_clean = {}\n",
    "    excluded = 0\n",
    "    for dataset in prompts_ground_truth:\n",
    "        contained = prompts_ground_truth[dataset]['foreign_key'].lower()  in fks_schemapile\n",
    "        if contained:\n",
    "            excluded += 1\n",
    "            print(dataset)\n",
    "        else:\n",
    "            prompts_ground_truth_clean[dataset] = prompts_ground_truth[dataset]\n",
    "            \n",
    "    print(\"Excluded: \"+str(excluded)+\"/\"+str(len(prompts_ground_truth)))\n",
    "    return prompts_ground_truth_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759facf0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "prompts_ground_truth_spider = clean_dataset_from_fk_pairs(json.load(open(f\"prompts_ground_truth_spider.json\")))\n",
    "prompts_ground_truth_bird = clean_dataset_from_fk_pairs(json.load(open(f\"prompts_ground_truth_bird.json\")))\n",
    "prompts_ground_truth_ctu = clean_dataset_from_fk_pairs(json.load(open(f\"prompts_ground_truth_ctu.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ctu_subsets = ['tpcc', 'tpce', 'tpcd']\n",
    "prompts_ground_truth_ctu_tpc_subset = {s: {} for s in ctu_subsets}\n",
    "for p in prompts_ground_truth_ctu:\n",
    "    for s in ctu_subsets:\n",
    "        if p.lower().startswith(s):\n",
    "            prompts_ground_truth_ctu_tpc_subset[s][p] = prompts_ground_truth_ctu[p]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0952d325",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc8cef57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_enums_from_prompt_text(prompt_text):\n",
    "    src = prompt_text.split(\"\\n\")[1]\n",
    "    trg = prompt_text.split(\"\\n\")[2]\n",
    "    src_table = src[:src.find(\"(\")]\n",
    "    src_cols = src[src.find(\"(\")+1:src.find(\")\")].split(\", \")\n",
    "    trg_table = trg[:trg.find(\"(\")]\n",
    "    trg_cols = trg[trg.find(\"(\")+1:trg.find(\")\")].split(\", \")\n",
    "    return src_table, src_cols, trg_table, trg_cols\n",
    "\n",
    "def generate_responses(prompts_ground_truth, method, output_file, recompute=False):\n",
    "    responses = {}\n",
    "    if os.path.exists(output_file) and not recompute:\n",
    "        responses = json.load(open(output_file))\n",
    "    \n",
    "    generate_response_as_json = method\n",
    "    for dataset_name in prompts_ground_truth:\n",
    "        if dataset_name in responses:\n",
    "            continue\n",
    "            \n",
    "        print(f\"determining fk's for: {dataset_name}\")\n",
    "        \n",
    "        prompt = prompts_ground_truth[dataset_name][\"prompt\"]\n",
    "        response_json = None\n",
    "        try:\n",
    "            response_json = generate_response_as_json(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"error with prompt {dataset_name}: {str(e)}\")\n",
    "        responses[dataset_name] = response_json\n",
    "        \n",
    "        with open(output_file, \"w+\") as f:\n",
    "            json.dump(responses, f)\n",
    "    return responses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece5b2f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## generate predictions t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec421c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "responses_t5_schemapile_spider = generate_responses(prompts_ground_truth_spider, \n",
    "                               generate_responses_as_json_t5, \"responses_t5_schemapile_spider.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc67a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "responses_t5_schemapile_bird = generate_responses(prompts_ground_truth_bird, \n",
    "                               generate_responses_as_json_t5, \"responses_t5_schemapile_bird.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73584df1",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "responses_t5_schemapile_ctu = generate_responses(prompts_ground_truth_ctu, \n",
    "                               generate_responses_as_json_t5, \"responses_t5_schemapile_ctu.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c141f60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## generate predictions starcoder-ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818edcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model, tokenizer, dialogue_template = initialize_model(\"../../data/starcoder-ctu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "responses_starcoder_ctu_spider = generate_responses(prompts_ground_truth_spider,\n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_ctu_spider.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generate predictions starcoder-ctu-peft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, tokenizer, dialogue_template = initialize_model(\"../../data/starcoder-ctu_peft\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "responses_starcoder_ctu_peft_spider = generate_responses(prompts_ground_truth_spider,\n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_ctu_spider.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "fd707c43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## generate predictions starcoder-schemapile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4852cd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model, tokenizer, dialogue_template = initialize_model(\"../../data/starcoder-schemapile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30bd107",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_starcoder_schemapile_spider = generate_responses(prompts_ground_truth_spider,\n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_schemapile_spider.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25367fd",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_starcoder_schemapile_bird = generate_responses(prompts_ground_truth_bird,\n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_schemapile_bird.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "566bf622",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_starcoder_schemapile_ctu = generate_responses(prompts_ground_truth_ctu,\n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_schemapile_ctu.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5f6e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## generate predictions starcoder alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2102a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model, tokenizer, dialogue_template = initialize_model(\"HuggingFaceH4/starchat-alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11a99c2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_starcoder_alpha_spider = generate_responses(prompts_ground_truth_spider, \n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_alpha_spider.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fee5efc4",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_starcoder_alpha_bird = generate_responses(prompts_ground_truth_bird, \n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_alpha_bird.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a64256",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_starcoder_alpha_ctu = generate_responses(prompts_ground_truth_ctu, \n",
    "                               generate_response_as_json_starcoder, \"responses_starcoder_alpha_ctu.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb965ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## generate predictions gpt3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cff927",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "responses_gpt35_spider = generate_responses(prompts_ground_truth_spider, \n",
    "                   generate_response_as_json_gpt35, \"responses_gpt35_spider.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abecf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "responses_gpt35_bird = generate_responses(prompts_ground_truth_bird, \n",
    "                   generate_response_as_json_gpt35, \"responses_gpt35_bird.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a4525",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "responses_gpt35_ctu = generate_responses(prompts_ground_truth_ctu, \n",
    "                   generate_response_as_json_gpt35, \"responses_gpt35_ctu.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541ec36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c23c67f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_responses(responses, prompts_ground_truth):\n",
    "    error = 0\n",
    "    match = 0\n",
    "    no_match = 0\n",
    "\n",
    "    for dataset_name in responses:\n",
    "        if dataset_name not in prompts_ground_truth:\n",
    "            print(f\"dataset {dataset_name} not found in ground truth, skipping\")\n",
    "            continue\n",
    "        \n",
    "        foreign_key_ground_truth = json.loads(prompts_ground_truth[dataset_name][\"foreign_key\"])\n",
    "        foreign_key_prediction = responses[dataset_name]\n",
    "        \n",
    "        if foreign_key_prediction is None:\n",
    "            error += 1\n",
    "            continue\n",
    "            \n",
    "        if (list(foreign_key_prediction.keys()) == list(foreign_key_ground_truth.keys()) and\n",
    "            (list(foreign_key_prediction.values()) == list(foreign_key_ground_truth.values()))):\n",
    "            match += 1\n",
    "        else:\n",
    "            no_match += 1  \n",
    "\n",
    "    print(\"match: \"+str(match))\n",
    "    print(\"no match: \"+str(no_match))\n",
    "    print(\"error: \"+str(error))\n",
    "    print(\"success rate: \"+str(match/(match+no_match+error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccc2d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_t5_schemapile_spider, prompts_ground_truth_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d404d9d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_t5_schemapile_bird, prompts_ground_truth_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b2c02",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_t5_schemapile_ctu, prompts_ground_truth_ctu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d4b45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_ctu_peft_spider, prompts_ground_truth_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbcdce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_ctu_spider, prompts_ground_truth_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc1bcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_gpt35_spider, prompts_ground_truth_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56c7c1",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_gpt35_bird, prompts_ground_truth_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33c43d",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_gpt35_ctu, prompts_ground_truth_ctu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bc4a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_alpha_spider, prompts_ground_truth_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe622e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_alpha_bird, prompts_ground_truth_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea8478",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_alpha_ctu, prompts_ground_truth_ctu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7c34d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_schemapile_spider, prompts_ground_truth_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11f7d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_schemapile_bird, prompts_ground_truth_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96865c5",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_responses(responses_starcoder_schemapile_ctu, prompts_ground_truth_ctu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "responses = {}\n",
    "for s in ctu_subsets:\n",
    "    match, no_match, error, rate = evaluate_responses(responses_starcoder_schemapile_ctu, prompts_ground_truth_ctu_tpc_subset[s])\n",
    "    responses[s] = (match, no_match, error, rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f06dba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define the models and group data\n",
    "models = ['jaccard', 'gpt-3.5', 'starcoder-alpha', 't5-schemapile', 'starcoder-schemapile']\n",
    "groups = ['spider', 'bird', 'ctu']\n",
    "group_data = np.array([[0.58, 0.88, 0.64, 0.92, 0.97], [0.63, 0.82,0.61, 0.83, 0.94], [0.36, 0.86, 0.82, 0.91, 0.97]])\n",
    "\n",
    "# Define a list of colors\n",
    "colors = sns.color_palette('deep')[0:5]\n",
    "\n",
    "barWidth = 0.15\n",
    "\n",
    "# Create bars\n",
    "for i in range(len(models)):  # for each model\n",
    "    r = [j + barWidth*i for j in range(len(groups))]\n",
    "    plt.bar(r, group_data[:, i], width=barWidth, color=colors[i], edgecolor='grey', label=models[i])\n",
    "\n",
    "# Adding xticks\n",
    "plt.xlabel('Groups', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(groups))], groups)\n",
    "\n",
    "# Add ylabel\n",
    "plt.ylabel('recall@k=1')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d392347",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}